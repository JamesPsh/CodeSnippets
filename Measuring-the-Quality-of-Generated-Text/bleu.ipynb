{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4256797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "BLEU Score(Bilingual Evaluation Understudy Score)\n",
    "https://wikidocs.net/31695\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087432c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "import nltk.translate.bleu_score as bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e9b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 된 문장(tokens)에서 n-gram을 카운트\n",
    "def simple_count(tokens, n):\n",
    "    \"\"\"\n",
    "    This function counts the occurrences of n-grams in the given list of tokens.\n",
    "\n",
    "    Args:\n",
    "        tokens (list): A list of tokens from a sentence.\n",
    "        n (int): The size of the n-gram. For example, use 1 for unigram, 2 for bigram, etc.\n",
    "\n",
    "    Returns:\n",
    "        Counter: A Counter dictionary that maps each n-gram to its frequency count.\n",
    "\n",
    "    Example:\n",
    "        >>> simple_count(['I', 'am', 'studying', 'NLP'], 2)\n",
    "        Counter({('I', 'am'): 1, ('am', 'studying'): 1, ('studying', 'NLP'): 1})\n",
    "\n",
    "    \"\"\"\n",
    "    # Use nltk's ngrams function to generate n-grams\n",
    "    # Then use Counter to count the frequency of each n-gram\n",
    "    return Counter(ngrams(tokens, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1107d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_clip(candidate, reference_list, n):\n",
    "    \"\"\"\n",
    "    This function calculates the clipped count of n-grams in the candidate sentence.\n",
    "\n",
    "    The clipped count of each n-gram is the minimum of its count in the candidate sentence\n",
    "    and its maximum count in any of the reference sentences.\n",
    "\n",
    "    Args:\n",
    "        candidate (list): A list of tokens from the candidate sentence.\n",
    "        reference_list (list of list): A list of lists of tokens from the reference sentences.\n",
    "        n (int): The size of the n-gram. For example, use 1 for unigram, 2 for bigram, etc.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary that maps each n-gram in the candidate sentence to its clipped count.\n",
    "\n",
    "    Example:\n",
    "        >>> count_clip(['I', 'am', 'studying', 'NLP'], [['I', 'am', 'learning', 'NLP']], 2)\n",
    "        {('I', 'am'): 1, ('am', 'studying'): 0, ('studying', 'NLP'): 1}\n",
    "\n",
    "    \"\"\"\n",
    "    # Count n-grams in the candidate sentence\n",
    "    ca_cnt = simple_count(candidate, n)\n",
    "    max_ref_cnt_dict = {}\n",
    "\n",
    "    # For each reference sentence\n",
    "    for ref in reference_list: \n",
    "        # Count n-grams in the reference sentence\n",
    "        ref_cnt = simple_count(ref, n)\n",
    "\n",
    "        # For each n-gram in the reference sentence, update its maximum count\n",
    "        for n_gram in ref_cnt:\n",
    "            max_ref_cnt_dict[n_gram] = max(ref_cnt[n_gram], max_ref_cnt_dict.get(n_gram, 0))\n",
    "\n",
    "    # Compute clipped counts\n",
    "    return {\n",
    "        # The clipped count of each n-gram is the minimum of its count in the candidate sentence\n",
    "        # and its maximum count in any of the reference sentences.\n",
    "        n_gram: min(ca_cnt.get(n_gram, 0), max_ref_cnt_dict.get(n_gram, 0)) for n_gram in ca_cnt\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4d0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_precision(candidate, reference_list, n):\n",
    "    \"\"\"\n",
    "    Calculate the modified precision of a candidate translation text.\n",
    "    Modified precision is a part of BLEU (Bilingual Evaluation Understudy) score calculation. \n",
    "    It measures how frequently the predicted n-grams appear in the reference text.\n",
    "    \n",
    "    Args:\n",
    "    candidate (list): The candidate translation text as a list of words.\n",
    "    reference_list (list): The reference translation texts as a list of words.\n",
    "    n (int): The size of the n-gram.\n",
    "    \n",
    "    Returns:\n",
    "    float: The modified precision score.\n",
    "    \"\"\"\n",
    "    # Count the maximum number of times that each n-gram occurs in any single reference translation\n",
    "    clip_cnt = count_clip(candidate, reference_list, n)\n",
    "\n",
    "    # Calculate the sum of clipped counts for the numerator of the modified precision\n",
    "    total_clip_cnt = sum(clip_cnt.values())\n",
    "\n",
    "    # Count the number of n-grams in the candidate translation\n",
    "    cnt = simple_count(candidate, n)\n",
    "\n",
    "    # Calculate the sum of counts for the denominator of the modified precision\n",
    "    total_cnt = sum(cnt.values())\n",
    "\n",
    "    # To avoid ZeroDivisionError if total count is 0\n",
    "    total_cnt = 1 if total_cnt == 0 else total_cnt\n",
    "\n",
    "    # Return the modified precision as the ratio of total clipped count to total count\n",
    "    return (total_clip_cnt / total_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15f6be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_ref_length(candidate, reference_list):\n",
    "    \"\"\"\n",
    "    Given a candidate string, find and return the length of the reference string that is closest in length to the candidate.\n",
    "\n",
    "    This function takes a candidate string and a list of reference strings as input, and returns the length of the reference string whose length is closest to the candidate string's length. \n",
    "    If there are multiple reference strings with the same length difference, it chooses the one with the shorter length.\n",
    "    \"\"\"\n",
    "    ca_len = len(candidate)\n",
    "    ref_lens = (len(ref) for ref in reference_list)\n",
    "    closest_ref_len = min(ref_lens, key=lambda ref_len: (abs(ref_len - ca_len), ref_len))\n",
    "    return closest_ref_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c24c5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brevity_penalty(candidate, reference_list):\n",
    "    \"\"\"Computes the brevity penalty for BLEU (Bilingual Evaluation Understudy) score calculation.\"\"\"\n",
    "\n",
    "    ca_len = len(candidate)\n",
    "    if ca_len == 0:\n",
    "        return 0\n",
    "\n",
    "    ref_len = closest_ref_length(candidate, reference_list)\n",
    "    return min(1.0, np.exp(1 - ref_len / ca_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f644826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(candidate, reference_list, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "    \"\"\"Computes the BLEU (Bilingual Evaluation Understudy) score for a candidate string.\"\"\"\n",
    "\n",
    "    # Compute the brevity penalty.\n",
    "    bp = brevity_penalty(candidate, reference_list)\n",
    "\n",
    "    # Compute the modified precision for each order of n-grams.\n",
    "    p_n = [modified_precision(candidate, reference_list, n=n) for n, _ in enumerate(weights,start=1)] \n",
    "\n",
    "    # Compute the weighted average of the log precisions, using the provided weights.\n",
    "    # score = np.sum([w_i * np.log(p_i) if p_i != 0 else 0 for w_i, p_i in zip(weights, p_n)])\n",
    "    score = np.sum([w_i * np.log(p_i + 1e-15) for w_i, p_i in zip(weights, p_n)])\n",
    "\n",
    "    # Return the BLEU score, which is the brevity penalty times the exponential of the average log precision.\n",
    "    return bp * np.exp(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "456df246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실습 코드의 BLEU : 0.5045666840058496\n",
      "패키지 NLTK의 BLEU : 0.5045666840058485\n"
     ]
    }
   ],
   "source": [
    "candidate = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "references = [\n",
    "    'It is a guide to action that ensures that the military will forever heed Party commands',\n",
    "    'It is the guiding principle which guarantees the military forces always being under the command of the Party',\n",
    "    'It is the practical guide for the army always to heed the directions of the party'\n",
    "]\n",
    "\n",
    "print('실습 코드의 BLEU :',bleu_score(candidate.split(),list(map(lambda ref: ref.split(), references))))\n",
    "print('패키지 NLTK의 BLEU :',bleu.sentence_bleu(list(map(lambda ref: ref.split(), references)),candidate.split()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
